{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The logistic map, fixed points, and the origins of chaos\n",
    "\n",
    "So far we have learned a lot about how a system switches from simple to chaotic motion, but *why* does this happen? And why is there a universal value for Feignbaum's $\\delta$ parameter? \n",
    "\n",
    "To develop answers to these questions we will move from the nonlinear pendulum to a very simple model which nonetheless displays period doubling and chaos. This \"toy model\" is called the logistic map:\n",
    "\n",
    "$$x_{n+1} = \\mu x_n(1-x_n)$$\n",
    "\n",
    "Much like our earlier integrations of ordinary differential equations, for the logistic map we compute the next value in the series from the previous one. In the 70's this model was used to describe the population dynamics of some critter when a resource (like food availability) limits population size. We wopn't worry about whether it is a good or bad model, or under what circumstances, we will instead use it to introduce the concept of a **fixed point.**\n",
    "\n",
    "The only control parameter is $\\mu$, and so let's explore the behavior as we vary $\\mu.$ First we explore what happens for $\\mu<3.0$, and vary the initial condition. Then increase $\\mu$ until it is $3.1$ or so. Then increase it beyond $3.5$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import math as math\n",
    "\n",
    "mu = 2.5 # controls regular vs chaotic behavior. mu > 3.56 for chaos. \n",
    "########## mu = 3.1 for period doubling\n",
    "x0 = 0.5 # initial population\n",
    "\n",
    "time = []\n",
    "x = []\n",
    "time.append(0)\n",
    "x.append(x0)\n",
    "\n",
    "\n",
    "imax = 200\n",
    "for i in range(1,imax):\n",
    "    xnew = mu*x[i-1]*(1-x[i-1])\n",
    "    time.append(i)\n",
    "    x.append(xnew)\n",
    "    \n",
    "plt.plot(time,x)\n",
    "plt.xlabel('time')\n",
    "plt.ylabel('$x$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fixed points\n",
    "\n",
    "Consider the case for small $\\mu$ which rapidly assumes a constant value for $x_n$, no matter the initial value of $x$. Apparently, our logistic map gets \"stuck\" on a particular value of $x$. If we let $f(x)$ be our mapping function:\n",
    "\n",
    "$$f(x) = \\mu x(1-x)$$\n",
    "\n",
    "then the value of $x$ that the system gets stuck on satisfies\n",
    "\n",
    "$$x^* = f(x^*)$$\n",
    "\n",
    "we call this special value $x^*$ a *fixed point.* We can understand the behavior in this regime by plotting the L.H.S of our map against the R.H.S. (the latter is an upside-down parabola):\n",
    "<img src=\"./logistic_map_1.png\" alt=\"log_map\" width=\"300\"/>\n",
    "\n",
    "What about period doubling? Let's replot the last figure, but now with a value of $\\mu$ which gives period doubling behavior. This changes the shape of the parabola, and now it intersects the line with unity slope in a different place...\n",
    "<img src=\"./logistic_map_2.png\" alt=\"log_map\" width=\"300\"/>\n",
    "\n",
    "If we follow the trajectory from some arbitrarily chosen initial condition, we see that the system bounces back and forth between two fixed points (after an initial transient that depends on the initial condition). There are now two \"stable\" fixed points, and the point where the line and the parabola and the line intersect is an unstable fixed point (more to follow). \n",
    "\n",
    "To see the origin of the three fixed points in the period doubling regime, let's consider the \"second iterate\" of our mapping function:\n",
    "\n",
    "$$f_2(x) = f(f(x))$$\n",
    "\n",
    "because we need to apply the map twice to bounce from one of the stable fixed points to the other in the period doubling regime. Note that the R.H.S. of the last equation is now a $4^{\\text th}$ order polynomial. If we plot the second iterate against a line of slope unity, we find three intersections:\n",
    "<img src=\"./logistic_map_3.png\" alt=\"log_map\" width=\"300\"/>\n",
    "\n",
    "Aha! there are the three fixed points. But how do we know which is stable, and which is unstable? For this we use one of our favorite Physics Tricks — perturbation. Imagine that we sit near one of the fixed points...a distance $\\delta x$ away, in fact. Then we can write down a Taylor expansion for the map function, stopping at the linear term:\n",
    "\n",
    "$$f(x^* + \\delta x) \\approx f(x^*) + f^{\\prime}(x^*)\\delta x$$\n",
    "\n",
    "Whether a fixed point is stable or unstable depends on whether the system gets closer to it or farther away as the map is iterated from a nearby point. This in turn depends on the slope of the (in this case, second iterate map) at $x^*$:\n",
    "\n",
    "$$\\begin{align}\n",
    "|f^{\\prime}(x^*)| < 1 & \\rightarrow \\text{stable fixed point} \\\\\n",
    "|f^{\\prime}(x^*)| > 1 & \\rightarrow \\text{unstable fixed point}\n",
    "\\end{align}$$\n",
    "\n",
    "because as we iterate we have $\\left[f^{\\prime}(x^*)\\right]^n$, and whether this increases or decreases in size is determined by the two cases. Note that the higher order terms do not change this conclusion.\n",
    "\n",
    "This also explains the universal behavior discussed last time. (Recall: many very different physical systems have universal values for the Feigenbaum constant, etc.) If we are close to a fixed point, the Taylor series looks the same for any system that has a quadratic mapping function. \n",
    "\n",
    "## On Random (but easy to describe) Numbers\n",
    "\n",
    "So far, we have considered deterministic problems. We have discovered \"unpredictable\" behavior in the sense of chaos, but it is not truly random: The exact sequence of values will repeat if started from the same initial condition. But we often want to simulate truly random processes. What if you want to to simulate flipping a coin? How can we do this in the computer?\n",
    "\n",
    "For this, we use algorithms called \"random number generators.\" There are many available, with esoteric sounding names like \"Mersenne Twister\" and \"xorshift.\" But how do they work? Indeed, how can a (deterministic) machine like a computer produce anything that is truly unpredictable?\n",
    "\n",
    "In fact, it cannot! The Mersenne Twister (and every other such algorithm) is a *pseudo*random number generator. Pseudorandom number generators apply chaotic maps (much more complex than the logistic map!) to produce a sequence of *random-looking* numbers. This means the sequence should satisfy certain properties:\n",
    "1. The digit sequence should be \"normal\" --- each digit appears with equal frequency\n",
    "2. The digit sequence should not repeat\n",
    "3. Sequences generated from different initial conditions should be different from one another\n",
    "4. An observer unaware of the algorithm used should be unable to predict the sequence\n",
    "\n",
    "Notice that a pseudorandom number generator requires an initial condition — in this area we call it a \"seed.\" If I use the same generator with the same seed, I get the same sequence...so they are not truly random, but deterministic. And yet, unpredictable (if it is a good generator) because of the properties of chaotic maps. \n",
    "\n",
    "Random number generators have a period...after all, computer arithmetic is finite, and so true chaos is impossible. You want a long period, because you might need a lot of random numbers for your simulation. If they repeat, you introduce an unphysical bias. The early literature is full of crap results because of bad random number generators. (The Mersenne Twister has a period of $2^{19937}-1$, and was only invented/discovered in 1998.)\n",
    "\n",
    "The last point is essential for cryptographic applications. Can an observer tell the difference between a pseudo-random sequence and a truly random sequence (as obtained from some physical process, like radioactive decay)? Of course, given enough data, an observer could, so the question must be posed more precisely. There are several statistical tests that a random number generator should pass in order to be cryptographically secure, but generally they amount to whether the algorithm can be cracked in polynomial time. (Quantum supremacy anyone?)\n",
    "\n",
    "Scratch off lottery tickets also use random number generators. How is it decided which tickets are the big winners? Pseudo-random algorithm. In some states (Texas, for example) the law requires that winning lottery ticket numbers be published. An observer is therefore availed of the sequence of digits. And an intelligent observer will be able to detect whether Texas used a crappy generator. Indeed, this has apparently happened, in Texas! Joan Ginther won a total of 20.4 million, winning 4 times, each time between 2 and 10 million$^1$. The chance of winning these 4 times is about $1/10^{42}$. \n",
    "\n",
    "Do you think she was just lucky? \n",
    "\n",
    "[1] \"The luckiest woman on earth,\" Nathaniel Rich in Haropers Magazine, August 2011"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
