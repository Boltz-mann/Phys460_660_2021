{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase transitions\n",
    "\n",
    "In this section we introduce some key ideas about phase transitions: What is a phase transition? How do they manifest in both experiments and simulations, and how should we think about them within the framework of statistical mechanics? What is the difference between a discontinuous and a continuous transition? In what way are critical points special? We will limit ourselves to fairly hand-waving arguments. For a more rigorous treatment, see \"Lectures on Phase Transitions and the Renormalization Group\" by Nigel Goldenfeld.\n",
    "\n",
    "## What is a phase transition?\n",
    "\n",
    "Consider the phase diagram in $T$ and $\\rho$ for the vdW fluid shown below. The curve delineates the coexistence region --- within this region, both the liquid and the vapor phase are stable. Thus if you increase the density of the fluid at constant temperature below $T_c$ (moving left to right), you begin forming droplets of the liquid when the boundary is reached. Once the other boundary is reached, all of the vapor has become liquid.  \n",
    "![vdw coexistence](./vdw_coexistence.jpg)\n",
    "Something different happens if you set $T=T_c$, the critical temperature. Here, the density of the liquid varies coninuously into the vapor. The shape of the coexistence curve near $T_c$ is:\n",
    "\n",
    "$$|\\rho - \\rho_c| \\propto |T - T_c|^{\\beta}  \\tag{Eq. 1}$$\n",
    "\n",
    "where $\\beta$ is called a *critical exponent.* For sulfur hexafluoride, $\\beta$ has been measured, and is equal to $0.327\\pm0.006$. For He$^3$, $\\beta = 0.321\\pm0.006$. For two total different fluids, the exponent $\\beta$ is identical, within experimental error.  It is also very different than the value that is obtained by a straightforward \"mean field\" calculation, which yields $\\beta = 1/2$. Other quantities, like the specific heat, diverge as $T_c$ is approached, also with \"universal\" critical exponents. What is going on here? Answering this question is one of the triumphs of physics in the second half of the 20th century.\n",
    "___\n",
    "**Question:** What thermodynamic property or function determines which phase is stable?\n",
    "___\n",
    "\n",
    "**The thermodynamic limit.**  Which phase is stable at a particular set of thermodynamic parameters is determined by the free energy --- the stable phase is the one with the lower free energy. At the boundary between phases, the free energy of the two phases is equal. The fact that different phases are stable on either side tells you that a phase transition has ocurred. But there is something weird here as well. Recall that the (Helmholtz) free energy is obtained from the partition function via:\n",
    "\n",
    "$$F = -k_BT\\text{ln}Z  \\tag{Eq. 2}$$\n",
    "\n",
    "This is an analytic function. How can nonanalytic behavior occur? (e.g., divergences in its derivatives) In fact, the free energy is analytic everywhere for a *finite system.* It is only in the thermodynamic limit that nonanalytic behavior is strictly possible. More on this later...but of course, your simulations are always finite.\n",
    "\n",
    "## The Ising model, with interactions\n",
    "\n",
    "In the third project you will work with the ferromagnetic Ising model, defined by the Hamiltonian:\n",
    "\n",
    "$$H(C) = -\\mu B \\sum_{i=i}^N\\sigma_i - J\\sum_{\\langle i,j \\rangle} \\sigma_i\\sigma_j  \\tag{Eq. 3}$$\n",
    "\n",
    "This innocent looking model is highly nontrivial --- the existence of a finite temperature phase transition at zero field and 2 dimensions was only proved in the 50's, and has never been proved for nonzero field. Likewise, the proof of a transition in $d=3$ awaits a brilliant young mind!\n",
    "\n",
    "The Ising model provides an opportunity to examine (albeit in a hand-waving way) the existence and nonexistence of phase transitions for a couple of cases. In the business of phase transitions and critical points, we will see that dimension and finite temperature play (ahem) critical roles. \n",
    "\n",
    "## Ising model: Phase transition at $\\bf{T=0}$.\n",
    "\n",
    "So, consider the ferromagnetic Ising model in d-dimensions, with $J>0$, and at $T=0$. Why $T=0$? Because there we need only consider the energy of the ground state! There is no entropy to compute, and no partition sum to compute (at least for classical models w/o degeracy). None of the excited states are occupied. Now imagine changing the values of the \"coupling constants\" $J$ and $B$, in the figure denoted $[K]$. (In general, there may be more than 2.) The lines in the figure below are the energies of the various states as the coupling parameters are varied. This suggests that the ground state changes as the couplings are varied --- A phase transition has occured! This mechanism is called \"level crossing.\"\n",
    "\n",
    "<img src=\"./level_cross.jpg\" alt=\"level_cross\" width=\"400\"/>\n",
    "\n",
    "For the ferromagnetic Ising model, the $\\sigma_i\\sigma_j$ term in the Hamiltonian is minimized by $\\sigma_i = \\sigma_j$. The term $-B\\sum\\sigma_i$ is minimized by\n",
    "\n",
    "$$ \\sigma_i = \\begin{cases}\n",
    "  +1 & \\text{if  } B > 0 \\\\\n",
    "  -1 & \\text{if  } B < 0\n",
    "  \\end{cases}$$\n",
    "\n",
    "Therefore, the ground state is \n",
    "\n",
    "$$ \\sigma_i = \\begin{cases}\n",
    "  +1 & \\text{if  } B > 0, J > 0 \\\\\n",
    "  -1 & \\text{if  } B < 0, J > 0\n",
    "  \\end{cases}$$\n",
    "  \n",
    "Therefore the ferromagnetic Ising model at $T=0$ has a phase transition at $B=0$.\n",
    "\n",
    "## Ising model: Finite temperature, d=1 \n",
    "\n",
    "Does this phase transition persist for finite temperature in the ferromagnetic Ising model? We will start with the $d=1$ case. This will allow us to introduce a key concept, which is the range over which spins are correlated. \n",
    "\n",
    "Note that in the $T=0$ case just discussed, the phases are ordered, in the sense that two spins separated by an arbitrarily large distance point in the same direction. This is clearly not the case for the paramagnet at high temperature. We therefore consider whether this \"long range order\" persists in the 1D Ising ferromagnet at $T \\neq 0$. \n",
    "\n",
    "Begin by considering the state with all spins up:\n",
    "\n",
    "$$\\uparrow\\uparrow\\uparrow\\cdots\\uparrow\\uparrow$$\n",
    "\n",
    "At nonzero $T$, inidivdual spins can flip by borrowing some energy from the thermal reservoir. For an infinite system, flipping a finite number of spins $n$ out of a total number $N$ will not destroy long range order, because\n",
    "\n",
    "$$\\lim_{N\\rightarrow \\infty}\\frac{N-n}{N}=1  \\tag{Eq. 4}$$\n",
    "\n",
    "Rather, we must flip a nonzero fraction $f$:\n",
    "\n",
    "$$\\lim_{N\\rightarrow \\infty}\\frac{N-fN}{N}<1  \\tag{Eq. 5}$$\n",
    "\n",
    "At $T=0$, the thermodynamics are entirely determined by the energies of the states, but now at nonzero $T$ we also have to consider the entropy. \n",
    "\n",
    "For the completely ordered state, the entropy is zero, and the free energy is simply\n",
    "\n",
    "$$F_{\\text{one_phase}}(N) = -NJ$$\n",
    "\n",
    "Now imagine creating a single \"domain wall:\"\n",
    "\n",
    "$$\\uparrow\\uparrow\\uparrow\\cdots\\uparrow\\uparrow\\downarrow\\downarrow\\cdots\\downarrow\\downarrow$$\n",
    "\n",
    "The introduction of the domain costs energy, but creates entropy. The cost is\n",
    "\n",
    "$$E(N) = -NJ + 2J  \\tag{Eq. 6}$$\n",
    "\n",
    "The entropy arises from the fact that the domain wall can be between any two spins:\n",
    "\n",
    "$$S(N) = k_B\\text{ln}N  \\tag{Eq. 7}$$\n",
    "\n",
    "And the free energy for this case (single domain wall separating a region of up spins from a region of down spins) is $F = U-TS$:\n",
    "\n",
    "$$F_{\\text{domain}}(N) = -NJ + 2J -k_BT\\text{ln}N \\tag{Eq. 7.5}$$ \n",
    "\n",
    "Thus the free energy difference between the all spins up (or down) case and the single domain wall case is\n",
    "\n",
    "$$\\Delta F(N) = F_{\\text{domain}} - F_{\\text{one phase}} = 2J - k_BT\\text{ln}N  \\tag{Eq. 8}$$\n",
    "\n",
    "Notice that for $N\\rightarrow\\infty$ the cost of the single domain wall remains fixed, while the entropy grows without bound. Therefore entropy \"wins\" for any finite temperature in $d=1$. Then of course you can split each domain in two by the same logic, and so on. Thus, no longe range order! We say that it is \"unstable with respect to thermal fluctuations.\"\n",
    "\n",
    "## Ising model: Finite temperature, d=2. \n",
    "\n",
    "In $d=2$, we consider flipping a contiguous block of spins. Now the entire boundary costs energy, because everywhere at the boundary there are pairs of antiparallel spins. If the boundary contains n such pairs, then the energy difference between a completely ordered state and one with a domain is \n",
    "\n",
    "$$\\Delta E = 2Jn  \\tag{Eq. 9}$$\n",
    "\n",
    "What about the entropy of the boundary? Consider all the different ways of drawing the boundary. If the lattice coordination is $z$, and the boundary consists of $n$ links between adjacent lattice sites, then an upper bound is $(z-1)^n$. ($z-1$ because the boundary can't retrace itself.) Therefore the difference in entropy between the completely ordered state and the single domain state is \n",
    "\n",
    "$$\\Delta S \\sim k_Bn\\text{ln}(z-1) \\tag{Eq. 10}$$\n",
    "\n",
    "and the the free energy to create a domain is \n",
    "\n",
    "$$\\Delta F(n) = [2J - k_BT\\text{ln}(z-1)]n \\tag{Eq. 11}$$\n",
    "\n",
    "In contrast to the previous case, now both the entropy and the cost of the boundary scale with the system size. But since only the entropy is scaled by $T$, there is a temperature above which entropy wins, and below which the cost to form the boundary wins. Where $\\Delta F$ flips from positive to negative we find the temperature at which the phase transiton occurs:\n",
    "\n",
    "$$T_c \\equiv \\frac{2J}{k_B\\text{ln}(z-1)} \\tag{Eq. 12}$$\n",
    "\n",
    "We note a couple things:\n",
    "1. The temperature $T_c$ is not universal --- it depends on the coordination of the lattice.\n",
    "2. If you cool the system down from above $T_c$, it will go from a disordered state (domains and boundaries) to an ordered state --- *in the absence of an external field!* How does it know whether to point all the spins up or down? It does not --- it spontaneously picks a direction. For this reason, this transition involves a *spontaneously broken symmetry.*\n",
    "\n",
    "## Power laws and scaling, and the correlation length\n",
    "\n",
    "In the arguments above, we leaned heavily on the magnetization in making our arguments about the existence of phase transitions in the Ising model. That is because the magentization discriminates between the ordered and disordered states. For that reason it is called an *order parameter.* In zero external field, the (spontaneous) magnetization of the ferromagnetic Ising model depends on temperature as shown in the figure:\n",
    "\n",
    "<img src=\"./Ising_transition.jpg\" alt=\"Ising phase diagram\" width=\"400\"/>\n",
    "\n",
    "Just as the density difference scales as a power law at the vdW critical point is approached, so too does the magnetization of the Ising model:\n",
    "\n",
    "$$m \\propto (T_c - T)^\\beta \\tag{Eq. 13}$$\n",
    "\n",
    "where we approach from below $T_c$. For the 2D ferromagnetic Ising model, $\\beta = 1/8$. (This was computed exactly by Lars Onsager in the 50's.) In d=3 the order parameter exponent has been measured experimentally, with $\\beta = 0.311 \\pm 0.005$ --- *the same as the vdW fluid!!* Although it has not been exactly computed in 3D, high precision computer simulations have verified the experimental measurements. \n",
    "\n",
    "What on earth is going on?!? How could two totally different systems be described by exactly the same physics at the critical point? This is an example of *universality,* and it arises because of the way spins (or density fluctuations) are corrleated in space near the critical point. To understand this, we need to introduce the correlation length.\n",
    "\n",
    "## Correlation length\n",
    "\n",
    "Consider a quantity that bears a resemblance to the autocorrelation function, but which we will simply call the correlation function:\n",
    "\n",
    "$$G(i,j) = \\langle \\sigma_i\\sigma_j \\rangle - \\langle \\sigma_i \\rangle \\langle \\sigma_j \\rangle \\tag{Eq. 14}$$\n",
    "\n",
    "This asks whether two spins are correlated or not, and generally depends on how close or far $i$ and $j$ are. Here is a visual example, which shows an Ising model at temperatures that increase from below $T_c$ to above $T_c$. \n",
    "<img src=\"./ising_model_configs.png\" alt=\"Ising phase diagram\" width=\"400\"/>\n",
    "Notice that at low temperature, there are large blocks of correlated spins --- the correlation length is large. At higher temperatures there are still domains of correlated spins, but they are smaller. At $T_c$ something special happens.\n",
    "\n",
    "Returning to $d=1$ for a moment, we saw that for any finite $T$ the spin chain is unstable with respect to thermal excitations, and therefore $\\langle \\sigma_i \\rangle = 0$. But what about $\\langle \\sigma_i\\sigma_j \\rangle$? \n",
    "\n",
    "For nearest neighbor spins ($j = i+1$) it can be shown by taking a derivative of $Z$ w.r.t. $J$ (here I only quote the result, but the method can be found in Goldenfeld, ch. 3): \n",
    "\n",
    "$$G(i, i+1) = \\langle \\sigma_i\\sigma_{i+1} \\rangle = \\text{tanh}(\\beta J) \\tag {Eq. 15}$$\n",
    "\n",
    "and for more distant pairs of spins:\n",
    "\n",
    "$$G(i, i+j) = \\langle \\sigma_i\\sigma_{i+j} \\rangle = \\text{tanh}^j(\\beta J) \\tag{Eq. 16}$$\n",
    "\n",
    "There are two possible cases. For $T = 0$, $G(i, i+j) = 1$ for all $j$ --- the system is perfectly correlated over all distances. This is the *long range order,* zero temperature state that we identified above. \n",
    "\n",
    "For $T\\neq0$, let's write $G(i, i+j)$ in a funny way, for reasons that will shortly be clear:\n",
    "\n",
    "$$G(i,i+j) = e^{-j\\text{ln}(\\text{coth}\\beta J)} \\tag{Eq. 17}$$\n",
    "\n",
    "(Work backwards to see that the R.H.S. equals $\\text{tanh}^j(\\beta J)$)\n",
    "\n",
    "For $T > 0$, $\\text{tanh}(\\beta J) < 1$ and  $\\text{coth}(\\beta J) > 1$. The correlation function can be written in a more compact form:\n",
    "\n",
    "$$G(i, i+j) = e^{-j/\\xi} \\tag{Eq. 18}$$\n",
    "\n",
    "where \n",
    "\n",
    "$$\\xi = \\frac{1}{\\text{ln}(\\text{coth}\\beta J)} \\tag{Eq. 19}$$\n",
    "\n",
    "The correlation length $\\xi$ is therefore the length over which spins are correlated. As $T \\rightarrow 0$, $\\xi$ diverges exponentially fast, while for $T > 0$ correlations decay exponentially. At critical points, however, we find a different behavior, which underlies scaling and universality.\n",
    "\n",
    "## Power law correlations\n",
    "\n",
    "We have already seen that the order parameter scales like $(T_c - T)^{\\beta}$ as the critical point is approached, and that $\\beta$ is the same for a wide class of models *and* experimental systems. Where does this mysterious behavior originate?\n",
    "\n",
    "Near a critical point, the correlation length also diverges, but not exponentially:\n",
    "\n",
    "$$\\xi = \\xi_0(T-T_c)^\\nu \\tag{Eq. 20}$$.\n",
    "\n",
    "For the Ising ferromagnet in $d=2$, $\\nu = 1$, and for $d=3$, $\\nu = 0.630$. *Near a critical point, correlations between spins occur on all spatial scales!* This is dramatically different than the exponential decay that is observed in the high temperature regime, where correlations decay exponentially over a length set by the exchange coupling $J/k_BT$. It is also dramatically different than the correlations near a first order transition, where the lengthscale of correlations is the droplet size. \n",
    "\n",
    "Near a critical point, *there is no characteristic size* --- this is why power law distributions are called \"scale free.\" This leads to a couple of important features:\n",
    "1. Because correlations exist over all scales, the microscopic physics becomes (nearly) irrelevant! The scaling is determined by the symmetry of the order parameter, the range of the interaction, and the dimension of the system. This is the origin of universal behavior.\n",
    "2. Long range correlations pose a difficulty for computer simulation, because near a critical point the finite size of the simulation lattice becomes evident. This manifests in several ways. In P3, you will see that $T_c$ is shifted, and singularities are \"rounded off.\"\n",
    "3. Clever people realized in the 80's that how observables scale with system size could be used to obtain precise estimates for critical exponents and temperatures from finite systems. Kurt Binder was (and is, he is 80 and still publishing) the unquestioned king in this area. I estimate that he has authored ca. 1,500 papers. This is almost certainly a record in physics.\n",
    "4. Ken Wilson, Leo Kadanoff, Ben Widom, Michael Fisher, and many others (including my PhD advisors Beate Schmittmann and Royce Zia) developed the theory to understand the origins of scaling and universality in statistical physics using the machinery of the renormalization group. The fact that the system is invariant under a change of scale suggest a transformation: groups of spins are \"blocked\" into coarse-grained degrees of freedom, which interact via new couplings. The way that these couplings \"run\" under successive transformations determines the essential physics at the critical point. (More on this below)\n",
    "5. The RG formulation also played an important role in simulations: It is hard to simulate a system near a critical point, because the dynamics slow down, because you have to wait for large domains to flip. Armed with knowledge about those domains from the RG, you can define sophisticated MC moves to identify collective spins flips. These algorithms are due originally to Bob Swendsen. \n",
    "\n",
    "## Real space RG, block spin transformations, and fixed points\n",
    "\n",
    "I'd like to give you an idea for how real-space renormalization works. This is a topic that deserves a couple weeks, not a single lecture, so we will be vague. But, you will get a sense for the origin of universality, and some insight into useful numerical algorithms for some hard stat mech problems. I am paraphrasing the arguments presented in Ch. 9 of Goldefeld, check it out for a more rigorous (but very approachable) trestment.\n",
    "\n",
    "Consider a transformation of our Ising variables called a \"block spin,\" which we carry out in the vicinity of the critical point: \n",
    "\n",
    "$$S_I \\equiv \\frac{1}{|\\bar{m}_\\ell|}\\frac{1}{\\ell^d}\\sum_{i\\in I}\\sigma_i \\tag{Eq. 21}$$\n",
    "\n",
    "with the average magnetization of the block \n",
    "\n",
    "$$\\bar{m}_\\ell \\equiv \\frac{1}{\\ell^d}\\sum_{i\\in I}\\langle\\sigma_i \\rangle \\tag{Eq. 22}$$\n",
    "\n",
    "This is a \"coarse-graining\" operation --- we sum/integrate over some microscopic variables (the $\\sigma$'s) to obtain an effective description over a longer lengthscale. Defined in this way, the coarse grained $S_I$'s are the same magnitude as the original spins:\n",
    "\n",
    "$$S_I = \\pm 1 \\tag{Eq. 23}$$\n",
    "\n",
    "The lengthscale $\\ell$ we choose to be between the lattice spacing $a$ and the correlation length $\\xi(T)$:\n",
    "\n",
    "$$a << \\ell a << \\xi(T) \\tag{Eq. 24}$$\n",
    "\n",
    "What does the Hamiltonian look like for the coarse-grained variables $S_I$? We won't go into great detail here, but notice that we have changed the *scale* of the problem. In the original (untransformed) version, the lattice spacing $a$ was the lengthscale. Now it is $\\ell a$...but the *physical value* of the correlation length $\\xi$ is unchanged. Consider the correlation length, from the point of view of the nondimensionalization/normalization that you do for numerical problems:\n",
    "\n",
    "$$\\xi = \\xi_\\ell(\\ell a) = \\xi_1 a \\tag{Eq. 25}$$\n",
    "\n",
    "which implies \n",
    "\n",
    "$$\\xi_\\ell = \\frac{\\xi_1}{\\ell} \\tag{Eq. 26}$$\n",
    "\n",
    "The transformed system is farther from criticality, which means that the coupling constants have changed accordingly. \n",
    "\n",
    "In the development of RG methods, Leo Kadanoff simply postulated the Hamiltonian to have the same form as the original (a big assumption that underlies the argument above), and was able to arrive at the scaling hypothesis (i.e., power law behavior at $T_c$ for $\\xi$, $m$, etc.) \n",
    "\n",
    "But this can't be correct. What if the original Hamiltonian had next-nearest neighbor interactions only? It would be ludicrous to assume that the transformed Hamiltonian only had next-nearest neighbor interactions! It was Ken Wilson who considered how the Hamiltomian transforms under repeated block spin transformations (and for which he won the Nobel Prize).\n",
    "\n",
    "The scaling transformation that we have described forms a semi-group: We will denote it be $R_\\ell$. For example, we can consider how the coupling constants $K$ (in the general case, this includes three-spin terms in $H$, four spin terms, etc.) transform under a change of scale:\n",
    "\n",
    "$$[K^\\prime] \\equiv R_\\ell[K] \\tag{Eq. 27}$$\n",
    "\n",
    "Under successive transformations, we obtain a series of Hamiltonians (the associative nature and lack of inversion makes this a semi-group).  How the coupling constants \"run\" under such transformations determines the phase diagram, and in the vicinity of a critial point, the critical exponents. Determining this \"flow\" is the goal of RG calculations. \n",
    "\n",
    "**Aside:** Implementing an RG transformation in practice requires implementing a \"projection operator\" then summing over the microscopic regrees of freedom --- we have to define how the block spins are obtained. Upon reflection, it is clear that this is a partial trace. Thus the RG point of view shifts us from thinking about computing the whole partition sum at once, to summing it in cleverly chosen pieces. That is how we handle the inifinities, by summing in such a way that they come only at the very end.\n",
    "\n",
    "## Fixed points \n",
    "\n",
    "Earlier, we argued that singular behavior can only occur in the thermodynamic limit. In the language of the RG, this means after an infinite number of RG transformations. Let's understand this idea by analogy. Consider a particle (overdamped) that rolls down a surface under gravity in the left panel of the figure. If the initial condition is anywhere to the left of $x_C$, it ends at $x_A$. To the right, it ends at $x_B$. The final position (right panel) is a discontinuos function of the initial position in the limit that $t \\rightarrow \\infty$. This arises despite the underlying analyticity of the potential. \n",
    "\n",
    "<img src=\"./fixed_points.jpg\" alt=\"fixed point\" width=\"400\"/>\n",
    "\n",
    "The set of initial conditions that flow to a given fixed point is its *basin of attraction.* Returning to the RG, the goal of calculations is to identify the fixed points in the space of coupling constants under repeated RG transformations. The fact that such fixed points exist is the origin of universality --- many Hamiltonians flow to the same fixed point. More precisely, at a fixed point $[K^*]$:\n",
    "\n",
    "$$[K^*] = R_\\ell[K^*] \\tag{Eq. 28}$$\n",
    "\n",
    "In the general case, a coarse-graining operation will map a Hamiltonian with only some couplings (nearest neighbor) onto a Hamiltonian with higher order couplings. However, near a critical point this no longer happens!\n",
    "\n",
    "As discussed earlier, the effective correlation length is reduced under an RG transformation:\n",
    "\n",
    "$$\\xi[K^*] = \\frac{\\xi[K]}{\\ell} \\tag{Eq. 29}$$\n",
    "\n",
    "but since this must be invariant at a fixed point:\n",
    "\n",
    "$$\\xi[K^*] = \\frac{\\xi[K^*]}{\\ell} \\tag{Eq. 30}$$\n",
    "\n",
    "which shows that $\\xi[K^*]$ can only be zero or infinity. The former is called a trivial fixed point, and the latter is a critical fixed point. Clearly the critical fixed point is associated with continuous phase transitions (diverging correlation length). The critical exponents are computed by examing the flows in $[K]$ near a critical fixed point. Identification of all the fixed points determines the phase diagram.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
